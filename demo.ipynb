{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf51f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c46ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 01:27:46.813634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from mingptf.model import GPT\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mingptf.utils import set_seed\n",
    "from mingptf.bpe import BPETokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from mingptf.utils import get_default_train_config\n",
    "from random import shuffle\n",
    "set_seed(3407)\n",
    "tokenizer = BPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c2a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128\n",
    "batch_size = 8\n",
    "epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a327293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_text has transfoerm code\n",
    "\"\"\"\n",
    "def get_sent_list(filename):\n",
    "    with open(filename) as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "    return lines\n",
    "\n",
    "def get_ids(seq):\n",
    "    return tokenizer(seq).numpy().tolist()[0]\n",
    "\n",
    "def pad_seq(inp):\n",
    "    return pad_sequences(inp, padding='post', maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "249c36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "lines = get_sent_list(\"./sample_text.txt\")\n",
    "shuffle(lines)\n",
    "print(len(lines))\n",
    "\n",
    "train = lines[:20]\n",
    "test = lines[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527fc954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 91, 437, 1659, 5239, 91, 29]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ids(\"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a99e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = pad_seq([get_ids(\"<|endoftext|>\"+seq) for seq in train])\n",
    "train_target = pad_seq([get_ids(seq+\"<|endoftext|>\") for seq in train])\n",
    "\n",
    "test_input = pad_seq([get_ids(\"<|endoftext|>\"+seq) for seq in test])\n",
    "test_target = pad_seq([get_ids(seq+\"<|endoftext|>\") for seq in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84eccbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (tf.data.Dataset.from_tensor_slices((train_input, train_target)).\n",
    "                shuffle(buffer_size=25000).\n",
    "                batch(batch_size).\n",
    "                repeat(epoch))\n",
    "test_data = (tf.data.Dataset.from_tensor_slices((test_input, test_target)).\n",
    "                shuffle(buffer_size=25000).\n",
    "                batch(batch_size).\n",
    "                repeat(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee37168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.24M\n"
     ]
    }
   ],
   "source": [
    "model_config = GPT.get_default_config()\n",
    "train_config = GPT.get_default_config()\n",
    "\n",
    "model_config.model_type = 'gpt-micro'\n",
    "\n",
    "\n",
    "model_config.vocab_size = 50257\n",
    "model_config.block_size = 128\n",
    "model = GPT(model_config)\n",
    "\n",
    "train_config = get_default_train_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "\n",
    "\n",
    "model.configure_optimizers(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fbd0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 80: train loss 47.20955: test loss 51.71170 : perplexity 1899033791622039541383168.00000\n",
      "Steps 85: train loss 52.81493: test loss 57.11445 : perplexity 35349099063452029006381056.00000\n",
      "Steps 90: train loss 16.32367: test loss 39.56030 : perplexity 195427420059205632.00000\n",
      "Steps 95: train loss 43.51852: test loss 68.83904 : perplexity 1650259242642114740603445650338611200.00000\n",
      "Steps 100: train loss 42.31688: test loss 50.71311 : perplexity 11115445704403898597376.00000\n",
      "Steps 105: train loss 28.92765: test loss 67.16721 : perplexity 294531313116797317694137084936192.00000\n",
      "Steps 110: train loss 56.56803: test loss 54.34906 : perplexity 486127875236799249907712.00000\n",
      "Steps 115: train loss 47.35986: test loss 60.51856 : perplexity 8111255750170134660017958158336.00000\n",
      "Steps 120: train loss 15.88312: test loss 73.68176 : perplexity 1734187061300400210174363440720642048.00000\n",
      "Steps 125: train loss 45.62486: test loss 54.42824 : perplexity 64432601089382143828126859264.00000\n",
      "Steps 130: train loss 38.27641: test loss 46.48086 : perplexity 162312774018618359808.00000\n",
      "Steps 135: train loss 16.29602: test loss 45.27392 : perplexity 214824235500363055104.00000\n",
      "Steps 140: train loss 32.40797: test loss 61.79636 : perplexity 184897119418638859438703771648.00000\n",
      "Steps 145: train loss 35.10524: test loss 74.24146 : perplexity 8377740027793202086985562249494528.00000\n",
      "Steps 150: train loss 21.37797: test loss 60.28926 : perplexity 7536777666906261302517170176.00000\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, test_data, test_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96474904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt='', num_samples=10, no_gen_tokens=20, no_samples=5, temperature=1, top_k=8):\n",
    "    x = tokenizer(prompt)\n",
    "    samples = []\n",
    "    for _ in range(no_samples):\n",
    "        y = model.generate(x, max_new_tokens=no_gen_tokens, \n",
    "                           temperature=temperature,\n",
    "                           top_k=top_k)\n",
    "        samples.append(tokenizer.decode(y.numpy()))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a22f0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def<    <     |     of  ',\n",
       " 'def    =<               ',\n",
       " 'def<     .< <   _      ',\n",
       " 'def  of < =      .       ',\n",
       " 'def                    ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(prompt='def')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f1b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingpt",
   "language": "python",
   "name": "mingpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
