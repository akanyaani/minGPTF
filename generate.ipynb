{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123da3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852c4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 20:59:52.544788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/abhaykumar/opt/anaconda3/envs/mingpt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mingptf.model import GPT\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mingptf.bpe import BPETokenizer\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29069ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mingpt = True # use minGPT or huggingface/transformers model?\n",
    "model_type = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b583e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 21:00:00.920091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 124.44M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfgpt2lm_head_model/transformer/wpe/embeddings:0 ---- gpt/wpe/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/wte/weight:0 ---- gpt/wte/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/gamma:0 ---- gpt/block/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/beta:0 ---- gpt/block/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_attn/weight:0 ---- gpt/block/causal_self_attention/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_proj/weight:0 ---- gpt/block/causal_self_attention/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/gamma:0 ---- gpt/block/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/beta:0 ---- gpt/block/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_fc/weight:0 ---- gpt/block/mlp/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0 ---- gpt/block/mlp/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/gamma:0 ---- gpt/block_1/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/beta:0 ---- gpt/block_1/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_attn/weight:0 ---- gpt/block_1/causal_self_attention_1/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_proj/weight:0 ---- gpt/block_1/causal_self_attention_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/gamma:0 ---- gpt/block_1/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/beta:0 ---- gpt/block_1/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_fc/weight:0 ---- gpt/block_1/mlp_1/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_proj/weight:0 ---- gpt/block_1/mlp_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/gamma:0 ---- gpt/block_2/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/beta:0 ---- gpt/block_2/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_attn/weight:0 ---- gpt/block_2/causal_self_attention_2/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_proj/weight:0 ---- gpt/block_2/causal_self_attention_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/gamma:0 ---- gpt/block_2/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/beta:0 ---- gpt/block_2/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_fc/weight:0 ---- gpt/block_2/mlp_2/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_proj/weight:0 ---- gpt/block_2/mlp_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/gamma:0 ---- gpt/block_3/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/beta:0 ---- gpt/block_3/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_attn/weight:0 ---- gpt/block_3/causal_self_attention_3/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_proj/weight:0 ---- gpt/block_3/causal_self_attention_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/gamma:0 ---- gpt/block_3/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/beta:0 ---- gpt/block_3/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_fc/weight:0 ---- gpt/block_3/mlp_3/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_proj/weight:0 ---- gpt/block_3/mlp_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/gamma:0 ---- gpt/block_4/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/beta:0 ---- gpt/block_4/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_attn/weight:0 ---- gpt/block_4/causal_self_attention_4/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_proj/weight:0 ---- gpt/block_4/causal_self_attention_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/gamma:0 ---- gpt/block_4/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/beta:0 ---- gpt/block_4/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_fc/weight:0 ---- gpt/block_4/mlp_4/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_proj/weight:0 ---- gpt/block_4/mlp_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/gamma:0 ---- gpt/block_5/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/beta:0 ---- gpt/block_5/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_attn/weight:0 ---- gpt/block_5/causal_self_attention_5/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_proj/weight:0 ---- gpt/block_5/causal_self_attention_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/gamma:0 ---- gpt/block_5/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/beta:0 ---- gpt/block_5/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_fc/weight:0 ---- gpt/block_5/mlp_5/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_proj/weight:0 ---- gpt/block_5/mlp_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/gamma:0 ---- gpt/block_6/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/beta:0 ---- gpt/block_6/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_attn/weight:0 ---- gpt/block_6/causal_self_attention_6/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_proj/weight:0 ---- gpt/block_6/causal_self_attention_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/gamma:0 ---- gpt/block_6/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/beta:0 ---- gpt/block_6/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_fc/weight:0 ---- gpt/block_6/mlp_6/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_proj/weight:0 ---- gpt/block_6/mlp_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/gamma:0 ---- gpt/block_7/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/beta:0 ---- gpt/block_7/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_attn/weight:0 ---- gpt/block_7/causal_self_attention_7/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_proj/weight:0 ---- gpt/block_7/causal_self_attention_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/gamma:0 ---- gpt/block_7/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/beta:0 ---- gpt/block_7/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_fc/weight:0 ---- gpt/block_7/mlp_7/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_proj/weight:0 ---- gpt/block_7/mlp_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/gamma:0 ---- gpt/block_8/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/beta:0 ---- gpt/block_8/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_attn/weight:0 ---- gpt/block_8/causal_self_attention_8/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_proj/weight:0 ---- gpt/block_8/causal_self_attention_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/gamma:0 ---- gpt/block_8/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/beta:0 ---- gpt/block_8/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_fc/weight:0 ---- gpt/block_8/mlp_8/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_proj/weight:0 ---- gpt/block_8/mlp_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/gamma:0 ---- gpt/block_9/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/beta:0 ---- gpt/block_9/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_attn/weight:0 ---- gpt/block_9/causal_self_attention_9/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_proj/weight:0 ---- gpt/block_9/causal_self_attention_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/gamma:0 ---- gpt/block_9/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/beta:0 ---- gpt/block_9/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_fc/weight:0 ---- gpt/block_9/mlp_9/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_proj/weight:0 ---- gpt/block_9/mlp_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/gamma:0 ---- gpt/block_10/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/beta:0 ---- gpt/block_10/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_attn/weight:0 ---- gpt/block_10/causal_self_attention_10/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_proj/weight:0 ---- gpt/block_10/causal_self_attention_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/gamma:0 ---- gpt/block_10/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/beta:0 ---- gpt/block_10/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_fc/weight:0 ---- gpt/block_10/mlp_10/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_proj/weight:0 ---- gpt/block_10/mlp_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/gamma:0 ---- gpt/block_11/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/beta:0 ---- gpt/block_11/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_attn/weight:0 ---- gpt/block_11/causal_self_attention_11/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_proj/weight:0 ---- gpt/block_11/causal_self_attention_11/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/gamma:0 ---- gpt/block_11/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/beta:0 ---- gpt/block_11/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_fc/weight:0 ---- gpt/block_11/mlp_11/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_proj/weight:0 ---- gpt/block_11/mlp_11/c_proj/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tfgpt2lm_head_model/transformer/ln_f/gamma:0 ---- gpt/ln_f/gamma:0\n",
      "tfgpt2lm_head_model/transformer/ln_f/beta:0 ---- gpt/ln_f/beta:0\n"
     ]
    }
   ],
   "source": [
    "if use_mingpt:\n",
    "    model = GPT.from_pretrained(model_type)\n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    model.config.pad_token_id = model.config.eos_token_id # suppress a warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6630cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51624c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849e631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer()\n",
    "hf_tokenizer = GPT2Tokenizer.from_pretrained(model_type)\n",
    "\n",
    "def generate(prompt='', num_samples=10, steps=20, do_sample=True):\n",
    "        \n",
    "    # tokenize the input prompt into integer input sequence\n",
    "    if use_mingpt:\n",
    "        if prompt == '':\n",
    "            # to create unconditional samples...\n",
    "            # manually create a tensor with only the special <|endoftext|> token\n",
    "            # similar to what openai's code does here https://github.com/openai/gpt-2/blob/master/src/generate_unconditional_samples.py\n",
    "            x = [[tokenizer.encoder.encoder['<|endoftext|>']]]\n",
    "        else:\n",
    "            x = tokenizer(prompt)\n",
    "    else:\n",
    "        if prompt == '': \n",
    "            # to create unconditional samples...\n",
    "            # huggingface/transformers tokenizer special cases these strings\n",
    "            prompt = '<|endoftext|>'\n",
    "        encoded_input = hf_tokenizer(prompt, return_tensors='tf').to(device)\n",
    "        x = encoded_input['input_ids']\n",
    "    \n",
    "    # we'll process all desired num_samples in a batch, so expand out the batch dim\n",
    "\n",
    "    # forward the model `steps` times to get samples, in a batch\n",
    "    y = model.generate(x, max_new_tokens=steps, top_k=40)\n",
    "    \n",
    "    out = tokenizer.decode(y.numpy())\n",
    "    print(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e7ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrej Karpathy, the chief executive officer of Karpathy Ventures, told Reuters.\"As we started looking at the markets we\n"
     ]
    }
   ],
   "source": [
    "generate(prompt='Andrej Karpathy, the', steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457fe26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingpt",
   "language": "python",
   "name": "mingpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
