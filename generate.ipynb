{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6097ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852c4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 20:36:48.895672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 20:36:48.895672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/abhaykumar/opt/anaconda3/envs/mingpt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/abhaykumar/opt/anaconda3/envs/mingpt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mingptf.model import GPT\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mingptf.bpe import BPETokenizer\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a2bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mingpt = True # use minGPT or huggingface/transformers model?\n",
    "model_type = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3747841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 20:36:56.848375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 20:36:56.848375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 124.44M\n",
      "number of parameters: 124.44M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfgpt2lm_head_model/transformer/wpe/embeddings:0 ---- gpt/wpe/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/wte/weight:0 ---- gpt/wte/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/wpe/embeddings:0 ---- gpt/wpe/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/wte/weight:0 ---- gpt/wte/embeddings:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/gamma:0 ---- gpt/block/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/beta:0 ---- gpt/block/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_attn/weight:0 ---- gpt/block/causal_self_attention/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_proj/weight:0 ---- gpt/block/causal_self_attention/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/gamma:0 ---- gpt/block/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/beta:0 ---- gpt/block/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_fc/weight:0 ---- gpt/block/mlp/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0 ---- gpt/block/mlp/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/gamma:0 ---- gpt/block_1/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/beta:0 ---- gpt/block_1/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_attn/weight:0 ---- gpt/block_1/causal_self_attention_1/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_proj/weight:0 ---- gpt/block_1/causal_self_attention_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/gamma:0 ---- gpt/block_1/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/beta:0 ---- gpt/block_1/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_fc/weight:0 ---- gpt/block_1/mlp_1/c_fc/kernel:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/gamma:0 ---- gpt/block/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_1/beta:0 ---- gpt/block/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_attn/weight:0 ---- gpt/block/causal_self_attention/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/attn/c_proj/weight:0 ---- gpt/block/causal_self_attention/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/gamma:0 ---- gpt/block/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/ln_2/beta:0 ---- gpt/block/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_fc/weight:0 ---- gpt/block/mlp/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0 ---- gpt/block/mlp/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/gamma:0 ---- gpt/block_1/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_1/beta:0 ---- gpt/block_1/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_attn/weight:0 ---- gpt/block_1/causal_self_attention_1/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/attn/c_proj/weight:0 ---- gpt/block_1/causal_self_attention_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/gamma:0 ---- gpt/block_1/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/ln_2/beta:0 ---- gpt/block_1/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_fc/weight:0 ---- gpt/block_1/mlp_1/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_proj/weight:0 ---- gpt/block_1/mlp_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/gamma:0 ---- gpt/block_2/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/beta:0 ---- gpt/block_2/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_attn/weight:0 ---- gpt/block_2/causal_self_attention_2/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_proj/weight:0 ---- gpt/block_2/causal_self_attention_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/gamma:0 ---- gpt/block_2/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/beta:0 ---- gpt/block_2/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_fc/weight:0 ---- gpt/block_2/mlp_2/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_proj/weight:0 ---- gpt/block_2/mlp_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/gamma:0 ---- gpt/block_3/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/beta:0 ---- gpt/block_3/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_attn/weight:0 ---- gpt/block_3/causal_self_attention_3/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_proj/weight:0 ---- gpt/block_3/causal_self_attention_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/gamma:0 ---- gpt/block_3/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/beta:0 ---- gpt/block_3/ln_2/beta:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._1/mlp/c_proj/weight:0 ---- gpt/block_1/mlp_1/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/gamma:0 ---- gpt/block_2/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_1/beta:0 ---- gpt/block_2/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_attn/weight:0 ---- gpt/block_2/causal_self_attention_2/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/attn/c_proj/weight:0 ---- gpt/block_2/causal_self_attention_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/gamma:0 ---- gpt/block_2/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/ln_2/beta:0 ---- gpt/block_2/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_fc/weight:0 ---- gpt/block_2/mlp_2/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._2/mlp/c_proj/weight:0 ---- gpt/block_2/mlp_2/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/gamma:0 ---- gpt/block_3/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_1/beta:0 ---- gpt/block_3/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_attn/weight:0 ---- gpt/block_3/causal_self_attention_3/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/attn/c_proj/weight:0 ---- gpt/block_3/causal_self_attention_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/gamma:0 ---- gpt/block_3/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/ln_2/beta:0 ---- gpt/block_3/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_fc/weight:0 ---- gpt/block_3/mlp_3/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_proj/weight:0 ---- gpt/block_3/mlp_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/gamma:0 ---- gpt/block_4/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/beta:0 ---- gpt/block_4/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_attn/weight:0 ---- gpt/block_4/causal_self_attention_4/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_proj/weight:0 ---- gpt/block_4/causal_self_attention_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/gamma:0 ---- gpt/block_4/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/beta:0 ---- gpt/block_4/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_fc/weight:0 ---- gpt/block_4/mlp_4/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_proj/weight:0 ---- gpt/block_4/mlp_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/gamma:0 ---- gpt/block_5/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/beta:0 ---- gpt/block_5/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_attn/weight:0 ---- gpt/block_5/causal_self_attention_5/c_attn/kernel:0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_fc/weight:0 ---- gpt/block_3/mlp_3/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._3/mlp/c_proj/weight:0 ---- gpt/block_3/mlp_3/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/gamma:0 ---- gpt/block_4/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_1/beta:0 ---- gpt/block_4/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_attn/weight:0 ---- gpt/block_4/causal_self_attention_4/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/attn/c_proj/weight:0 ---- gpt/block_4/causal_self_attention_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/gamma:0 ---- gpt/block_4/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/ln_2/beta:0 ---- gpt/block_4/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_fc/weight:0 ---- gpt/block_4/mlp_4/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._4/mlp/c_proj/weight:0 ---- gpt/block_4/mlp_4/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/gamma:0 ---- gpt/block_5/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_1/beta:0 ---- gpt/block_5/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_attn/weight:0 ---- gpt/block_5/causal_self_attention_5/c_attn/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_proj/weight:0 ---- gpt/block_5/causal_self_attention_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/gamma:0 ---- gpt/block_5/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/beta:0 ---- gpt/block_5/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_fc/weight:0 ---- gpt/block_5/mlp_5/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_proj/weight:0 ---- gpt/block_5/mlp_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/gamma:0 ---- gpt/block_6/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/beta:0 ---- gpt/block_6/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_attn/weight:0 ---- gpt/block_6/causal_self_attention_6/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_proj/weight:0 ---- gpt/block_6/causal_self_attention_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/gamma:0 ---- gpt/block_6/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/beta:0 ---- gpt/block_6/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_fc/weight:0 ---- gpt/block_6/mlp_6/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_proj/weight:0 ---- gpt/block_6/mlp_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/attn/c_proj/weight:0 ---- gpt/block_5/causal_self_attention_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/gamma:0 ---- gpt/block_5/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/ln_2/beta:0 ---- gpt/block_5/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_fc/weight:0 ---- gpt/block_5/mlp_5/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._5/mlp/c_proj/weight:0 ---- gpt/block_5/mlp_5/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/gamma:0 ---- gpt/block_6/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_1/beta:0 ---- gpt/block_6/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_attn/weight:0 ---- gpt/block_6/causal_self_attention_6/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/attn/c_proj/weight:0 ---- gpt/block_6/causal_self_attention_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/gamma:0 ---- gpt/block_6/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/ln_2/beta:0 ---- gpt/block_6/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_fc/weight:0 ---- gpt/block_6/mlp_6/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._6/mlp/c_proj/weight:0 ---- gpt/block_6/mlp_6/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/gamma:0 ---- gpt/block_7/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/beta:0 ---- gpt/block_7/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_attn/weight:0 ---- gpt/block_7/causal_self_attention_7/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_proj/weight:0 ---- gpt/block_7/causal_self_attention_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/gamma:0 ---- gpt/block_7/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/beta:0 ---- gpt/block_7/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_fc/weight:0 ---- gpt/block_7/mlp_7/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_proj/weight:0 ---- gpt/block_7/mlp_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/gamma:0 ---- gpt/block_8/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/beta:0 ---- gpt/block_8/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_attn/weight:0 ---- gpt/block_8/causal_self_attention_8/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_proj/weight:0 ---- gpt/block_8/causal_self_attention_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/gamma:0 ---- gpt/block_8/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/beta:0 ---- gpt/block_8/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_fc/weight:0 ---- gpt/block_8/mlp_8/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/gamma:0 ---- gpt/block_7/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_1/beta:0 ---- gpt/block_7/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_attn/weight:0 ---- gpt/block_7/causal_self_attention_7/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/attn/c_proj/weight:0 ---- gpt/block_7/causal_self_attention_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/gamma:0 ---- gpt/block_7/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/ln_2/beta:0 ---- gpt/block_7/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_fc/weight:0 ---- gpt/block_7/mlp_7/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._7/mlp/c_proj/weight:0 ---- gpt/block_7/mlp_7/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/gamma:0 ---- gpt/block_8/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_1/beta:0 ---- gpt/block_8/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_attn/weight:0 ---- gpt/block_8/causal_self_attention_8/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/attn/c_proj/weight:0 ---- gpt/block_8/causal_self_attention_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/gamma:0 ---- gpt/block_8/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/ln_2/beta:0 ---- gpt/block_8/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_fc/weight:0 ---- gpt/block_8/mlp_8/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_proj/weight:0 ---- gpt/block_8/mlp_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/gamma:0 ---- gpt/block_9/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/beta:0 ---- gpt/block_9/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_attn/weight:0 ---- gpt/block_9/causal_self_attention_9/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_proj/weight:0 ---- gpt/block_9/causal_self_attention_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/gamma:0 ---- gpt/block_9/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/beta:0 ---- gpt/block_9/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_fc/weight:0 ---- gpt/block_9/mlp_9/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_proj/weight:0 ---- gpt/block_9/mlp_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/gamma:0 ---- gpt/block_10/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/beta:0 ---- gpt/block_10/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_attn/weight:0 ---- gpt/block_10/causal_self_attention_10/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_proj/weight:0 ---- gpt/block_10/causal_self_attention_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/gamma:0 ---- gpt/block_10/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/beta:0 ---- gpt/block_10/ln_2/beta:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._8/mlp/c_proj/weight:0 ---- gpt/block_8/mlp_8/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/gamma:0 ---- gpt/block_9/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_1/beta:0 ---- gpt/block_9/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_attn/weight:0 ---- gpt/block_9/causal_self_attention_9/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/attn/c_proj/weight:0 ---- gpt/block_9/causal_self_attention_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/gamma:0 ---- gpt/block_9/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/ln_2/beta:0 ---- gpt/block_9/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_fc/weight:0 ---- gpt/block_9/mlp_9/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._9/mlp/c_proj/weight:0 ---- gpt/block_9/mlp_9/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/gamma:0 ---- gpt/block_10/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_1/beta:0 ---- gpt/block_10/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_attn/weight:0 ---- gpt/block_10/causal_self_attention_10/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/attn/c_proj/weight:0 ---- gpt/block_10/causal_self_attention_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/gamma:0 ---- gpt/block_10/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/ln_2/beta:0 ---- gpt/block_10/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_fc/weight:0 ---- gpt/block_10/mlp_10/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_proj/weight:0 ---- gpt/block_10/mlp_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/gamma:0 ---- gpt/block_11/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/beta:0 ---- gpt/block_11/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_attn/weight:0 ---- gpt/block_11/causal_self_attention_11/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_proj/weight:0 ---- gpt/block_11/causal_self_attention_11/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/gamma:0 ---- gpt/block_11/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/beta:0 ---- gpt/block_11/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_fc/weight:0 ---- gpt/block_11/mlp_11/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_proj/weight:0 ---- gpt/block_11/mlp_11/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/ln_f/gamma:0 ---- gpt/ln_f/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_fc/weight:0 ---- gpt/block_10/mlp_10/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._10/mlp/c_proj/weight:0 ---- gpt/block_10/mlp_10/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/gamma:0 ---- gpt/block_11/ln_1/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_1/beta:0 ---- gpt/block_11/ln_1/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_attn/weight:0 ---- gpt/block_11/causal_self_attention_11/c_attn/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/attn/c_proj/weight:0 ---- gpt/block_11/causal_self_attention_11/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/gamma:0 ---- gpt/block_11/ln_2/gamma:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/ln_2/beta:0 ---- gpt/block_11/ln_2/beta:0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_fc/weight:0 ---- gpt/block_11/mlp_11/c_fc/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/h_._11/mlp/c_proj/weight:0 ---- gpt/block_11/mlp_11/c_proj/kernel:0\n",
      "0.0\n",
      "tfgpt2lm_head_model/transformer/ln_f/gamma:0 ---- gpt/ln_f/gamma:0\n",
      "tfgpt2lm_head_model/transformer/ln_f/beta:0 ---- gpt/ln_f/beta:0\n",
      "tfgpt2lm_head_model/transformer/ln_f/beta:0 ---- gpt/ln_f/beta:0\n"
     ]
    }
   ],
   "source": [
    "if use_mingpt:\n",
    "    model = GPT.from_pretrained(model_type)\n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    model.config.pad_token_id = model.config.eos_token_id # suppress a warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b54a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d675c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096e2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8c8a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[31373]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[31373]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faffbea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'gpt' (type GPT).\n\ntoo many values to unpack (expected 2)\n\nCall arguments received by layer 'gpt' (type GPT):\n  • x=tf.Tensor(shape=(1, 1, 1), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhei\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/model.py:282\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, tokenizer, context, max_new_tokens, temperature, top_k)\u001b[0m\n\u001b[1;32m    280\u001b[0m past \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m--> 282\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# print(logits)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(temperature, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mingpt/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/model.py:153\u001b[0m, in \u001b[0;36mGPT.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m mask \u001b[38;5;241m=\u001b[39m create_masks(x)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mif seq len is 4 then mask looks like this\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m       [[0., 1., 1., 1.],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m        [0., 0., 0., 0.]]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m b, t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[1;32m    155\u001b[0m pos \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;241m0\u001b[39m, t), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    156\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(x)  \u001b[38;5;66;03m# Converting ids to word embeddings\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'gpt' (type GPT).\n\ntoo many values to unpack (expected 2)\n\nCall arguments received by layer 'gpt' (type GPT):\n  • x=tf.Tensor(shape=(1, 1, 1), dtype=int32)"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'gpt' (type GPT).\n\ntoo many values to unpack (expected 2)\n\nCall arguments received by layer 'gpt' (type GPT):\n  • x=tf.Tensor(shape=(1, 1, 1), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhei\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/model.py:282\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, tokenizer, context, max_new_tokens, temperature, top_k)\u001b[0m\n\u001b[1;32m    280\u001b[0m past \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m--> 282\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# print(logits)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(temperature, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mingpt/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/model.py:153\u001b[0m, in \u001b[0;36mGPT.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m mask \u001b[38;5;241m=\u001b[39m create_masks(x)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mif seq len is 4 then mask looks like this\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m       [[0., 1., 1., 1.],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m        [0., 0., 0., 0.]]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m b, t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[1;32m    155\u001b[0m pos \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;241m0\u001b[39m, t), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    156\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(x)  \u001b[38;5;66;03m# Converting ids to word embeddings\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'gpt' (type GPT).\n\ntoo many values to unpack (expected 2)\n\nCall arguments received by layer 'gpt' (type GPT):\n  • x=tf.Tensor(shape=(1, 1, 1), dtype=int32)"
     ]
    }
   ],
   "source": [
    "model.generate(tokenizer, context=\"hei\", max_new_tokens=10, temperature=1, top_k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b23c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt='', num_samples=10, steps=20, do_sample=True):\n",
    "        \n",
    "    # tokenize the input prompt into integer input sequence\n",
    "    if use_mingpt:\n",
    "        tokenizer = BPETokenizer()\n",
    "        if prompt == '':\n",
    "            # to create unconditional samples...\n",
    "            # manually create a tensor with only the special <|endoftext|> token\n",
    "            # similar to what openai's code does here https://github.com/openai/gpt-2/blob/master/src/generate_unconditional_samples.py\n",
    "            x = torch.tensor([[tokenizer.encoder.encoder['<|endoftext|>']]], dtype=torch.long)\n",
    "        else:\n",
    "            x = tokenizer(prompt).to(device)\n",
    "    else:\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_type)\n",
    "        if prompt == '': \n",
    "            # to create unconditional samples...\n",
    "            # huggingface/transformers tokenizer special cases these strings\n",
    "            prompt = '<|endoftext|>'\n",
    "        encoded_input = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "        x = encoded_input['input_ids']\n",
    "    \n",
    "    # we'll process all desired num_samples in a batch, so expand out the batch dim\n",
    "    x = x.expand(num_samples, -1)\n",
    "\n",
    "    # forward the model `steps` times to get samples, in a batch\n",
    "    y = model.generate(x, max_new_tokens=steps, do_sample=do_sample, top_k=40)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        out = tokenizer.decode(y[i].cpu().squeeze())\n",
    "        print('-'*80)\n",
    "        print(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec523433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json to /Users/abhaykumar/.cache/mingpt/encoder.json\n",
      "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json to /Users/abhaykumar/.cache/mingpt/encoder.json\n",
      "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe to /Users/abhaykumar/.cache/mingpt/vocab.bpe\n",
      "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe to /Users/abhaykumar/.cache/mingpt/vocab.bpe\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAndrej Karpathy, the\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt, num_samples, steps, do_sample)\u001b[0m\n\u001b[1;32m     10\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[tokenizer\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mencoder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m'\u001b[39m]]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_type)\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/bpe.py:273\u001b[0m, in \u001b[0;36mBPETokenizer.__call__\u001b[0;34m(self, text, return_tensors)\u001b[0m\n\u001b[1;32m    270\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mencode(text)]\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# wrap into TF tensor\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# wrap into TF tensor\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(idx, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'float'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAndrej Karpathy, the\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt, num_samples, steps, do_sample)\u001b[0m\n\u001b[1;32m     10\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[tokenizer\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mencoder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m'\u001b[39m]]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_type)\n",
      "File \u001b[0;32m~/myprojects/minGPTF/mingptf/bpe.py:273\u001b[0m, in \u001b[0;36mBPETokenizer.__call__\u001b[0;34m(self, text, return_tensors)\u001b[0m\n\u001b[1;32m    270\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mencode(text)]\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# wrap into TF tensor\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# wrap into TF tensor\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(idx, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "generate(prompt='Andrej Karpathy, the', num_samples=10, steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952f945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingpt",
   "language": "python",
   "name": "mingpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
